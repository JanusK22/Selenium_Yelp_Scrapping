{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38361de-ee46-490a-935b-e5fbc9be6028",
   "metadata": {},
   "source": [
    "# Data aquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a14586-aa34-408c-a321-2fff5fc92914",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54131105880433a8d7fa7b6db3a03ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basilique du Sacré-Cœur de Montmartre  processed...\n",
      "The Hardware Société  processed...\n",
      "Le Temps des Cerises  processed...\n",
      "La Droguerie du Marais  processed...\n",
      "La Crêperie de Josselin  processed...\n",
      "Le Cinq  processed...\n",
      "Hank  processed...\n",
      "Le Hide  processed...\n",
      "Le Petit Canard  processed...\n",
      "Pyramide du Louvre  processed...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "from concurrent import futures\n",
    "from datetime import datetime\n",
    "\n",
    "import chromedriver_autoinstaller\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "chromedriver_autoinstaller.install()\n",
    "op = webdriver.ChromeOptions()\n",
    "op.add_argument(\"--disable-extensions\")\n",
    "op.add_argument(\"--headless\")\n",
    "op.add_argument(\"--disable-gpu\")\n",
    "op.add_argument(\"--no-sandbox\")\n",
    "op.add_argument(\"--window-size=1200x600\")\n",
    "op.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "\n",
    "# Creating a Google Driver for Selenium\n",
    "driver_Create = lambda: webdriver.Chrome(options=op)\n",
    "\n",
    "# config\n",
    "cfg = yaml.safe_load(open(\"config.yml\", \"r\"))\n",
    "\n",
    "# Config\n",
    "method = cfg[\"method\"]  # one #fast #defined\n",
    "base = cfg[\"base\"]\n",
    "city = cfg[\"city\"]\n",
    "thread = cfg[\"thread\"]\n",
    "shops = cfg[\"shops\"]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Name\",\n",
    "        \"href\",\n",
    "        \"Rating\",\n",
    "        \"Name_reviewer\",\n",
    "        \"Rating_reviewer\",\n",
    "        \"Elite\",\n",
    "        \"Ort_reviewer\",\n",
    "        \"Friends_count\",\n",
    "        \"Reviews_count\",\n",
    "        \"Pictures_count\",\n",
    "        \"Date\",\n",
    "        \"Comment\",\n",
    "        \"Names_pictures\",\n",
    "        \"Hilfreich\",\n",
    "        \"Lustig\",\n",
    "        \"Cool\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Querry infos for every page\n",
    "def get_pages(page_, driver_, rest_review):\n",
    "    global df\n",
    "    global pbar\n",
    "\n",
    "    driver_.implicitly_wait(10)\n",
    "    driver_.get(page_[1])\n",
    "\n",
    "    def get_review_rating(page_, driver_, rest_review, retry):\n",
    "        allnull = False\n",
    "        try:\n",
    "            # print(\"test \",page_[0])\n",
    "            if rest_review == -1:\n",
    "                try:\n",
    "                    rest_review = WebDriverWait(driver_, 10).until(\n",
    "                        EC.presence_of_element_located(\n",
    "                            (\n",
    "                                By.XPATH,\n",
    "                                '//*[@id=\"wrap\"]/div[2]/yelp-react-root/div[1]/div[3]/div[1]/div[1]/div/div/div[2]/div[2]/span',\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                    rest_review = dig(rest_review.text)\n",
    "                except:\n",
    "                    allnull = True\n",
    "                    rest_review = 0\n",
    "            try:\n",
    "                rating = WebDriverWait(driver_, 10).until(\n",
    "                    EC.presence_of_element_located(\n",
    "                        (\n",
    "                            By.XPATH,\n",
    "                            '//*[@id=\"wrap\"]/div[2]/yelp-react-root/div[1]/div[3]/div[1]/div[1]/div/div/div[2]/div[1]/span/div',\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                rating = float(rating.get_attribute(\"aria-label\")[:2])\n",
    "                allnull = False\n",
    "            except:\n",
    "                rating = \"\"\n",
    "            try:\n",
    "                reviews = driver_.find_elements(\n",
    "                    By.CLASS_NAME,\n",
    "                    \"review__373c0__3MsBX.border-color--default__373c0__1WKlL\",\n",
    "                )\n",
    "                allnull = False\n",
    "            except:\n",
    "                reviews = []\n",
    "            reviewer_rating = driver_.find_elements(\n",
    "                By.CLASS_NAME, \"i-stars__373c0___sZu0\"\n",
    "            )\n",
    "            rest_review -= 10\n",
    "            return reviews, rating, reviewer_rating, rest_review\n",
    "        except:\n",
    "            if retry == 10:\n",
    "                print(\"Error by :\", page_[0])\n",
    "                return \"error\"\n",
    "\n",
    "            retry += 1\n",
    "            if allnull:\n",
    "                print(\"Retry get_review_rating for \", page_[0], \" :\", retry)\n",
    "                get_review_rating(page_, driver_, rest_review, retry)\n",
    "\n",
    "    reviews, rating, reviewer_rating, rest_review = get_review_rating(\n",
    "        page_, driver_, rest_review, 0\n",
    "    )\n",
    "    if reviews == \"error\":\n",
    "        rest_review -= 10\n",
    "        return\n",
    "\n",
    "    if len(reviews) != 0:\n",
    "        for stack, i in enumerate(reviews):\n",
    "            # name , ort , friends , reviews , pictures ,date  , comment , name_photos ,Hilfreich , lustig, Cool\n",
    "            liste = i.text.split(\"\\n\")\n",
    "\n",
    "            try:\n",
    "                rew_rat = reviewer_rating[stack + 2]\n",
    "                rew_rat = float(rew_rat.get_attribute(\"aria-label\")[:2])\n",
    "            except:\n",
    "                print(\n",
    "                    \"error in reviews by getting rating in\",\n",
    "                    page_[0],\n",
    "                    \"for\",\n",
    "                    str(stack + 1) + \".\",\n",
    "                    \"review\",\n",
    "                )\n",
    "                rew_rat = 0\n",
    "\n",
    "            try:\n",
    "                x = 1 if \"Elite\" in liste[1] else 0\n",
    "                elite = {1: \"Yes\", 0: \"No\"}\n",
    "\n",
    "                try:\n",
    "                    pictures_count = dig(liste[6 + x])\n",
    "                except:\n",
    "                    pictures_count = 0\n",
    "\n",
    "                review = {\n",
    "                    \"Name\": page_[0],\n",
    "                    \"href\": page_[1],\n",
    "                    \"Rating\": rating,\n",
    "                    \"Name_reviewer\": liste[0],\n",
    "                    \"Rating_reviewer\": rew_rat,\n",
    "                    \"Elite\": elite[x],\n",
    "                    \"Ort_reviewer\": liste[1 + x],\n",
    "                    \"Friends_count\": liste[2 + x],\n",
    "                    \"Reviews_count\": liste[3 + x],\n",
    "                    \"Pictures_count\": pictures_count,\n",
    "                    \"Hilfreich\": dig(liste[-3]),\n",
    "                    \"Lustig\": dig(liste[-2]),\n",
    "                    \"Cool\": dig(liste[-1]),\n",
    "                }\n",
    "\n",
    "                re_date = r\"\\d{1,2}.\\d{1,2}.\\d{1,4}\"\n",
    "                if re.match(re_date, liste[5 + x]):\n",
    "                    review[\"Date\"] = liste[5 + x]\n",
    "                else:\n",
    "                    review[\"Date\"] = \"\"\n",
    "\n",
    "                if pictures_count <= 4:\n",
    "                    review[\"Names_pictures\"] = \" \".join(\n",
    "                        liste[-3 - pictures_count - x : -3]\n",
    "                    )\n",
    "                    review[\"Comment\"] = \" \".join(liste[7 + x : -3 - pictures_count - x])\n",
    "                else:\n",
    "                    review[\"Names_pictures\"] = \"\"\n",
    "                    review[\"Comment\"] = \" \".join(liste[7 + x : -4])\n",
    "\n",
    "                df = df.append([review], ignore_index=True)\n",
    "            except:\n",
    "                print(\n",
    "                    \"error in reviews by:\",\n",
    "                    page_[0],\n",
    "                    \"for\",\n",
    "                    str(stack + 1) + \".\",\n",
    "                    \"review\",\n",
    "                )\n",
    "    else:\n",
    "        df = df.append(\n",
    "            [{\"Name\": page_[0], \"href\": page_[1], \"Rating\": rating}], ignore_index=True\n",
    "        )\n",
    "\n",
    "    if rest_review > 0:\n",
    "        # driver3 = driver_Create()\n",
    "        get_pages(page_, driver_, rest_review)\n",
    "    else:\n",
    "        print(page_[0], \" processed...\")\n",
    "        pbar.update(1)\n",
    "        driver_.close()\n",
    "        driver_.quit()\n",
    "\n",
    "\n",
    "# Querry all shops link and names\n",
    "def get_shops(driver_):\n",
    "    global df\n",
    "    try:\n",
    "        class_name = driver_.find_element(\n",
    "            By.XPATH,\n",
    "            '//*[@id=\"main-content\"]/div/ul/li[4]/div/div/div/div[2]/div[1]/div[1]/div[1]/div/div/h4/span/a',\n",
    "        )\n",
    "    except:\n",
    "        print(\"except\")\n",
    "        class_name = driver_.find_element(\n",
    "            By.XPATH,\n",
    "            '//*[@id=\"main-content\"]/div/ul/li[4]/div/div/div/div[2]/div[1]/div/div[1]/div/div[1]/div/div/h4/span/a',\n",
    "        )\n",
    "    class_name = class_name.get_attribute(\"class\")\n",
    "    classes = driver_.find_elements(By.CLASS_NAME, class_name)\n",
    "    for i in classes:\n",
    "        if (i.get_attribute(\"href\")).find(\"biz\") != -1:\n",
    "            page = [i.get_attribute(\"name\"), i.get_attribute(\"href\")]\n",
    "            driver2 = driver_Create()\n",
    "            get_pages(page, driver2, -1)\n",
    "\n",
    "\n",
    "# Get dig in a word\n",
    "def dig(word):\n",
    "    a = re.findall(r\"\\d+\", word)\n",
    "    a = int(a[-1]) if len(a) != 0 else 0\n",
    "    return a\n",
    "\n",
    "\n",
    "# get total number of pages\n",
    "base_driver = driver_Create()\n",
    "base_driver.get(f\"https://www.yelp.de/search?cflt={shops}&find_loc={city}\")\n",
    "total_pages = WebDriverWait(base_driver, 10).until(\n",
    "    EC.presence_of_element_located(\n",
    "        (By.XPATH, '//*[@id=\"main-content\"]/div/ul/li[14]/div/div[2]/span')\n",
    "    )\n",
    ")\n",
    "\n",
    "total_pages = dig(total_pages.text)\n",
    "base_driver.quit()\n",
    "\n",
    "# total_pages = thread\n",
    "pbar = tqdm(total=total_pages * 10)\n",
    "\n",
    "# Proccesing the scraper for the given city\n",
    "def proc(url):\n",
    "    global city\n",
    "    driver = driver_Create()\n",
    "    driver.get(base + f\"search?cflt={shops}&find_loc=\" + city + \"&start=\" + str(url))\n",
    "    driver.implicitly_wait(10)\n",
    "    get_shops(driver)\n",
    "\n",
    "\n",
    "if method == \"defined\":\n",
    "    # Multiprocessing with defined Chunk\n",
    "    with futures.ThreadPoolExecutor() as executor:  # default/optimized number of threads\n",
    "        total_pages = [i * 10 for i in range(total_pages)]\n",
    "        chunk = [\n",
    "            total_pages[i : i + thread] for i in range(0, len(total_pages), thread)\n",
    "        ]\n",
    "        for i in chunk:\n",
    "            executor.map(proc, i)\n",
    "\n",
    "elif method == \"fast\":\n",
    "    # Multiprocessing with max perf\n",
    "    with futures.ThreadPoolExecutor() as executor:  # default/optimized number of threads\n",
    "        executor.map(proc, [i * 10 for i in range(total_pages)])\n",
    "\n",
    "elif method == \"one\":\n",
    "    # One by one\n",
    "    for i in range(total_pages):\n",
    "        proc(i * 10)\n",
    "\n",
    "\n",
    "pbar.close()\n",
    "df.to_csv(\n",
    "    f\"datas/data {city}'s {shops} {datetime.now().strftime('%d-%m-%Y')} {base.split('.')[-1][:-1]}.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
